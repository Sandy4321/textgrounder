///////////////////////////////////////////////////////////////////////////////
//  CellDist.scala
//
//  Copyright (C) 2010-2014 Ben Wing, The University of Texas at Austin
//
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.
///////////////////////////////////////////////////////////////////////////////

package opennlp.textgrounder
package gridlocate

import collection.mutable

import util.error.warning
import util.print.errprint

import langmodel.{Gram,LangModel}

/**
 * Probability distribution over cells. Instances of this class are normally
 * generated by `CellDistFactory`.

 * @param cellprobs List of cells and associated probabilities
 * @param normalized Whether the probability distribution is normalized
 */

class CellDist[Co](
  val cellprobs: Iterable[(GridCell[Co], Double)],
  val normalized: Boolean
) {
  /**
   * Return a ranked list of all the cells. We may need to add the
   * specified correct cell to the list. See `Ranker.evaluate`.
   */
  def get_ranked_cells(correct: Option[GridCell[Co]],
      include_correct: Boolean): IndexedSeq[(GridCell[Co], Double)] = {
    val probs =
      if (!include_correct)
        cellprobs
      else
        // Elements on right override those on left
        Map(correct.get -> 0.0) ++ cellprobs.toMap
    // sort by second element of tuple, in reverse order
    probs.toIndexedSeq sortWith (_._2 > _._2)
  }
}

/**
 * Factory object for creating CellDists, i.e. objects describing a
 * probability distribution over cells.
 */
class CellDistFactory[Co] {
  /**
   * Create normalized cell dist from unnormalized dist.
   */
  def create_normalized_cell_dist(cellprobs: Iterable[(GridCell[Co], Double)]
  ) = {
    // Normalize the probabilities; but if all probabilities are 0, then
    // we can't normalize, so leave as-is. This will happen, for example,
    // for words never seen in the entire corpus.
    val totalprob = cellprobs.map(_._2).sum
    val (normalized, norm_cellprobs) =
      if (totalprob == 0)
        (false, cellprobs)
      else
        (true, cellprobs.map { case (cell, prob) => (cell, prob / totalprob) })

    new CellDist[Co](norm_cellprobs, normalized)
  }

  /**
   * Create a distribution over cells from the number of documents in
   * each cell.
   */
  def get_cell_dist_from_doc_count(grid: Grid[Co]) = {
    create_normalized_cell_dist(grid.iter_nonempty_cells.map { cell =>
      (cell, cell.num_docs.toDouble)
    })
  }

  /**
   * Create a distribution over cells that is associated with a gram,
   * based on the relative probabilities of the gram in the language models
   * of the various cells.  That is, if we have a set of cells, each with a
   * language model, then we can imagine conceptually inverting the process
   * to generate a cell distribution over grams.  Basically, for a given gram,
   * look to see what its probability is in all cells; normalize, and we have
   * a cell distribution.
   */
  def get_cell_dist(grid: Grid[Co], gram: Gram) = {
    create_normalized_cell_dist(grid.iter_nonempty_cells.map { cell =>
      (cell, cell.grid_lm.gram_prob(gram))
    })
  }

  /**
   * Return a cell distribution over a language model, in the form of a
   * list of pairs of cells and probabilities.  This works
   * by adding up the language models of the individual grams,
   * weighting by the count of the each gram.
   */
  def get_cell_dist_for_lang_model[Co](grid: Grid[Co],
      lang_model: LangModel) = {
    val base_cells = grid.iter_nonempty_cells
    val parallel = !grid.driver.params.no_parallel
    val cells =
      if (parallel)
        base_cells.par
      else
        base_cells

    val norm_factors = lang_model.iter_grams.map { case (gram, count) =>
      val raw_factor =
        cells.map(cell => cell.grid_lm.gram_prob(gram)).sum
      val norm_factor =
        if (raw_factor == 0)
          1.0
        else
          1.0/raw_factor
      (gram, count * norm_factor)
    }
    val cellprobs = cells.map { cell =>
      val cellprob = norm_factors.map { case (gram, factor) =>
        factor * cell.grid_lm.gram_prob(gram)
      }.sum
      (cell, cellprob)
    }
    // Renormalize to produce a probability distribution; but if all
    // probabilities are 0, then we can't normalize, so leave as-is.
    // This will happen, for example, for words never seen in the entire
    // corpus.
    val totalprob = cellprobs.map(_._2).sum
    val (normalized, total_norm_factor) =
      if (totalprob == 0)
        (false, 1.0)
      else
        (true, 1.0/totalprob)
    val normed_cell_probs =
      cellprobs.map { case (cell, cellprob) =>
        (cell, total_norm_factor * cellprob)
      }
    new CellDist[Co](normed_cell_probs.toIndexedSeq, normalized)
  }
}
